# Semantic Communication System (SemCom-Project)

## Project Vision & End Goal
You are building a complete **Semantic Communication System** that consists of both encoder and decoder components.  
The system aims to compress natural language into semantic representations (triples) for efficient communication, then reconstruct meaningful information at the receiver end.

**Aimed - System Architecture Overview:**

```
[USER INPUT]
"Einstein developed the theory of relativity"
        â†“
[TRIPLE EXTRACTION] â† Your current work
"Einstein|developed|theory of relativity"
        â†“
[SEMANTIC EMBEDDING] â† Next stage
[0.23, -0.45, 0.78, ..., 0.12] (128-dim vector)
        â†“
[VECTOR QUANTIZATION] â† Compression stage
[23, 156, 78, 12] (4 indices instead of 128 floats)
        â†“
[CHANNEL CODING] â† Error protection
[23, 156, 78, 12, 45, 67] (6 bits with redundancy)
        â†“
[TRANSMISSION] â† Over wireless channel
Radio waves/5G/WiFi
        â†“
[CHANNEL DECODING] â† Error correction
[23, 156, 78, 12] (recovered indices)
        â†“
[VECTOR DEQUANTIZATION] â† Decompression
[0.23, -0.45, 0.78, ..., 0.12] (restored vector)
        â†“
[SEMANTIC DECODING] â† Text reconstruction
"Einstein|developed|theory of relativity"
        â†“
[TRIPLE-TO-TEXT] â† Natural language generation
"Einstein developed the theory of relativity"
        â†“
[USER DISPLAY]
Received message

```


- **Current Focus:** Working on the **ENCODER** part (triple extraction stage) to convert natural language sentences into structured semantic triples.

---

## Project Structure & File Organization

**Local Laptop Directory Structure:**

```
SEMANTIC COMMS/
â”œâ”€ .vscode/
â”œâ”€ data/
â”‚  â”œâ”€ processed/
â”‚  â””â”€ raw/
â”‚     â””â”€ sample-1.json
â”œâ”€ results/
â”œâ”€ docs/
â”œâ”€ logs/
â”‚  â””â”€ logs.md
â”œâ”€ model_extraction/                    # â† ENCODER STAGE
â”‚  â”œâ”€ data/
â”‚  â”‚  â””â”€ labeled_triples.json
â”‚  â”œâ”€ scripts/
â”‚  â”‚  â””â”€ run_inference.py
â”‚  â””â”€ trained/
â”‚     â””â”€ flan-t5-triple-extraction-final/
â”‚        â”œâ”€ config.json
â”‚        â”œâ”€ generation_config.json
â”‚        â”œâ”€ model.safetensors
â”‚        â”œâ”€ special_tokens_map.json
â”‚        â”œâ”€ spiece.model
â”‚        â”œâ”€ tokenizer_config.json
â”‚        â”œâ”€ tokenizer.json
â”‚        â””â”€ training_args.bin
â”œâ”€ reports/
â”œâ”€ src/
â”‚  â”œâ”€ decoding/                        # â† DECODER STAGE (Future work)
â”‚  â”œâ”€ encoding/                        # â† ENCODER STAGE (Current work)
â”‚  â””â”€ extraction/
â”‚     â””â”€ extracting_entities.py
â”œâ”€ utils/
â”œâ”€ tests/
â”œâ”€ .gitignore
â”œâ”€ README.md
â””â”€ requirements.txt
```

---

## Complete System Workflow

### Stage 1: ENCODER (Current Work - Triple Extraction)
- **Input:** Natural language sentences  
- **Process:** Extract semantic triples using fine-tuned Flan-T5  
- **Output:** Structured triples (`subject|relation|object`)  
- **Status:** âœ… Model trained, ðŸš¨ Output quality issues  

### Stage 2: DECODER (Future Work - Text Reconstruction)
- **Input:** Semantic triples  
- **Process:** Reconstruct meaningful text from triples  
- **Output:** Natural language sentences  
- **Status:** âŒ Not started yet  


### Development Environment
```
transformers>=4.0
torch>=1.9
datasets
numpy
pandas
```

### Hardware
- **Training:** Google Colab (free tier)  
- **Development:** Local Windows laptop  
- **Inference:** CPU/GPU automatic detection  




